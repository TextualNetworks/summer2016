<h1>Computational Approaches to Textual Networks</h1>

<p>"Computational Approaches to Textual Networks" is the first collaborative research venture of the DHRX: Digital Humanities Research Network at Pitt (http://dhrx.pitt.edu).</p>

<p>Funded by University of Pittsburgh's Special Initiative to Promote Scholarship in the Humanities and Creative Arts and the University of Pittsburgh English Department's Digtal Media Lab, 
the project begins in summer 2016. During this period, two half-time graduate gtudent assistants will work to jumpstart the process of assembling two research datasets related to textual networks: </p>

<ul>
<li>1) a collection of book reviews for bestselling books (according to Publisher’s Weekly’s records) from 1912 to 1922, and </li>
<li>2) the acknowledgments from a set of approximately 6,000 doctoral dissertations in the field of Rhetoric, Composition, and Writing Studies from 1980 to 2015. Challenges in processing these materials through machine-based Natural Language Processing (NLP) include poor performance of optical character recognition (OCR) on certain materials (e.g. a pulp magazine or a dissertation composed on a typewriter) and inconsistent usage of proper names, which can lead to erroneous duplication and missed references. Funding for a one-term GSA would allow us to create workflow models (including digitization, data modeling, and data curation) to address these challenges, and thus to generate machine-readable textual corpora with strong relational attributes. These experiments and workflows, moreover, have strong potential to generalize to additional datasets. </li>
</ul>
<p>Known challenges in processing textual materials with important network properties through machine-based Natural Language Processing 
(NLP) include poor performance of optical character recognition (OCR) on certain materials (e.g. a pulp magazine or a dissertation composed on a typewriter) and inconsistent usage of proper names, which can lead to erroneous duplication and missed references. Funding for a one-term GSA would allow us to create workflow models (including digitization, data modeling, and data curation) to address these challenges, and thus to generate machine-readable textual corpora with strong relational attributes. These experiments and workflows, moreover, have strong potential to generalize to additional datasets. </p>

<p>Experience of the project team includes the following: </p>

<p>Alison Langmead, who is the Director of the Visual Media Workshop in the Department of the History of Art and Architecture, an Assistant Professor in the School of Information Sciences, and also the Principal Contact for the DHRX, contributes considerable expertise in the domain of data modeling, metadata construction, and collaborative team-building.</p> 

<p>Matthew Lavin, Clinical Assistant Professor of English and Director of the Digital Media Lab in English and an active member of the DHRX, has experience with large-scale, computational text analysis, computer aided authorship attribution, FRBR, linked data, and late-19th and early-20th century histories of publishing and print.</p>

<p>Benjamin Miller, who is Assistant Professor of English, lead developer of the academic genealogy site The Writing Studies Tree (http://writingstudiestree.org), and an active member of the DHRX, has experience with network visualization, relationship schemata, and computational text analysis. </p>

<p>Annette Vee, Assistant Professor of English and author of several articles and a book (Coding Literacy, MIT 2016) on the connections between computer programming and writing, contributes a theoretical perspective on the relationships between texts and processes.</p>

<p>Our graduate student assistants are:</p>
<p>Daniel Libertz</p>
<p>Lucia LoTempio</p>
